{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "# Evaluation of completion results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/space/Documents/projects/REX/re-evaluate/experiments/re-test-template/lib/dispatcher/src already in sys.path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "lib_dir = os.path.abspath(os.path.join(os.path.curdir, \"lib/dispatcher/src\"))\n",
    "if lib_dir not in sys.path:\n",
    "    print(f\"Adding {lib_dir} to sys.path\")\n",
    "    sys.path.insert(0, lib_dir)\n",
    "else:\n",
    "    print(f\"{lib_dir} already in sys.path\")\n",
    "\n",
    "os.environ[\"APP_CONFIG_DIR\"] = os.path.abspath(os.path.join(os.path.curdir, \"lib/dispatcher/config\"))\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.path.curdir, \"..\", \"..\", \"eval-data\"))\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 responses from /Users/space/Documents/projects/REX/re-evaluate/eval-data/responses/sample-occ-uce-mc-exam.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "qa_source_file = 'sample-occ-uce-mc-exam.json'\n",
    "\n",
    "qa_input_file = os.path.join(data_path, \"responses\", qa_source_file)\n",
    "\n",
    "with open(qa_input_file, 'r') as f:\n",
    "    file_data = f.read()\n",
    "    qa_data = json.loads(file_data)\n",
    "\n",
    "print(f\"Loaded {len(qa_data.get(\"eval-questions\"))} responses from {qa_input_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 3 test case(s) in parallel: |██████████|100% (3/3) [Time Taken: 00:08,  2.94s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 0.8181818181818182, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.82 because the main response effectively identifies the benchmarks for measuring liquidity risk. However, introductory and unrelated interactive elements in the answer slightly diverge from the main focus, preventing it from reaching a perfect score. Keep up the great work; focusing on direct, targeted information can help achieve an even higher score!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Which two benchmarks are used to measure liquidity risk?\n",
      "  - actual output: Hello, this is Erin, the enterprise assistant. To measure liquidity risk, the two main benchmarks used are:\n",
      "\n",
      "1. Current Ratio: This is calculated by dividing a company's current assets by its current liabilities. It indicates a company's ability to pay its short-term obligations using its current assets.\n",
      "\n",
      "2. Quick Ratio (Acid-Test Ratio): This is calculated by dividing a company's most liquid current assets (cash, marketable securities, and accounts receivable) by its current liabilities. It provides a more stringent measure of a company's ability to meet its short-term obligations using its most liquid assets.\n",
      "\n",
      "These ratios help assess a company's liquidity and its capacity to meet its short-term financial commitments. Let me know if you need any clarification or have additional questions!\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 0.9090909090909091, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.91 because the response effectively addresses the question about the Economic Value of Equity and its measurement purpose. However, it includes a greeting that is not directly relevant to the topic, preventing a perfect score. Still, the high score reflects the response's strong focus and precision in explaining the concept., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the Economic Value of Equity used to measure?\n",
      "  - actual output: Hello, this is Erin, the enterprise assistant. The Economic Value of Equity (EVE) is a measure used to assess the overall value of a company's equity or ownership. It is calculated by taking the market value of a company's assets and subtracting the market value of its liabilities.\n",
      "\n",
      "The EVE provides an estimate of the net worth or intrinsic value of a company from the perspective of its shareholders. It takes into account the company's assets, liabilities, and the market's valuation of the business. \n",
      "\n",
      "Some key points about the Economic Value of Equity:\n",
      "\n",
      "- It represents the value of the company that would be available to shareholders if the company were to be liquidated and all liabilities were paid off.\n",
      "- A higher EVE indicates the company has more valuable assets compared to its liabilities, suggesting stronger shareholder value.\n",
      "- EVE can be used to compare the relative value of different companies or to track changes in a company's value over time.\n",
      "- It provides a different perspective than book value, which does not account for market valuations.\n",
      "\n",
      "Please let me know if you have any other questions! I'm happy to provide more details about this financial metric.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 0.9375, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.94 because the response comprehensively addressed the factors contributing to a bank's net interest margin decline, showing an excellent grasp of the topic. However, the introductory greeting 'Hello, this is Erin, the enterprise assistant.' was introductory and not directly related to the question, slightly impacting the score., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What would cause a bank's net interest margin to decline?\n",
      "  - actual output: Hello, this is Erin, the enterprise assistant. Regarding your question about a bank's net interest margin declining, there are a few potential factors that could contribute to this:\n",
      "\n",
      "1. Falling interest rates: When interest rates decline, banks typically earn less on their interest-earning assets (such as loans) compared to the interest they pay on their interest-bearing liabilities (such as deposits). This can compress the net interest margin.\n",
      "\n",
      "2. Increased competition: If there is intense competition in the banking sector, it may force banks to offer higher deposit rates or lower loan rates, which can squeeze the net interest margin.\n",
      "\n",
      "3. Changes in the loan portfolio mix: If a bank shifts its loan portfolio towards lower-yielding assets, such as mortgages or consumer loans, it can lead to a decline in the overall yield on the loan portfolio, reducing the net interest margin.\n",
      "\n",
      "4. Rising funding costs: If a bank's cost of funding, such as the interest it pays on deposits or wholesale borrowings, increases faster than the yield on its interest-earning assets, it can cause the net interest margin to decline.\n",
      "\n",
      "5. Regulatory changes: Certain regulatory requirements, such as higher capital or liquidity standards, can increase a bank's funding costs and put pressure on its net interest margin.\n",
      "\n",
      "I hope this overview of potential factors helps provide some context around the decline in a bank's net interest margin. Please let me know if you have any other questions.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.  \n",
       "‼️ Looking for a place for your LLM test data to live 🏡? Use Confident AI for test reports, benchmark analysis, \n",
       "compare models/prompts, and catch regressions for your LLM system.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.  \n",
       "‼️ Looking for a place for your LLM test data to live 🏡? Use Confident AI for test reports, benchmark analysis, \n",
       "compare models/prompts, and catch regressions for your LLM system.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8181818181818182, 0.9090909090909091, 0.9375]\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "\n",
    "\n",
    "metric = AnswerRelevancyMetric(threshold=0.5)\n",
    "test_cases = [LLMTestCase(\n",
    "    input=response.get(\"question\"),\n",
    "    actual_output=response.get(\"response\")\n",
    ") for response in qa_data.get(\"eval-questions\")]\n",
    "\n",
    "# metric.measure(test_cases)\n",
    "# print(metric.score)\n",
    "# print(metric.reason)\n",
    "\n",
    "score_data = evaluate(test_cases, [metric])\n",
    "scores = [r.metrics_data[0].score for r in score_data.test_results]\n",
    "print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qa, s in zip(qa_data.get(\"eval-questions\"), scores):\n",
    "    qa[\"score-answer-relevance\"] = s\n",
    "\n",
    "output_file = os.path.join(data_path, \"scores\", f\"{qa_source_file}.scored.json\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(json.dumps(qa_data, indent=2))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
